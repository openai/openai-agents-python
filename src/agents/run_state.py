"""RunState class for serializing and resuming agent runs with human-in-the-loop support."""

from __future__ import annotations

import json
from dataclasses import dataclass, field
from typing import TYPE_CHECKING, Any, Generic

from typing_extensions import TypeVar

from ._run_impl import NextStepInterruption
from .exceptions import UserError
from .items import ToolApprovalItem
from .logger import logger
from .run_context import RunContextWrapper
from .usage import Usage

if TYPE_CHECKING:
    from .agent import Agent
    from .guardrail import InputGuardrailResult, OutputGuardrailResult
    from .items import ModelResponse, RunItem

TContext = TypeVar("TContext", default=Any)
TAgent = TypeVar("TAgent", bound="Agent[Any]", default="Agent[Any]")

# Schema version for serialization compatibility
CURRENT_SCHEMA_VERSION = "1.0"


@dataclass
class RunState(Generic[TContext, TAgent]):
    """Serializable snapshot of an agent's run, including context, usage, and interruptions.

    This class allows you to:
    1. Pause an agent run when tools need approval
    2. Serialize the run state to JSON
    3. Approve or reject tool calls
    4. Resume the run from where it left off

    While this class has publicly writable properties (prefixed with `_`), they are not meant to be
    used directly. To read these properties, use the `RunResult` instead.

    Manipulation of the state directly can lead to unexpected behavior and should be avoided.
    Instead, use the `approve()` and `reject()` methods to interact with the state.
    """

    _current_turn: int = 0
    """Current turn number in the conversation."""

    _current_agent: TAgent | None = None
    """The agent currently handling the conversation."""

    _original_input: str | list[Any] = field(default_factory=list)
    """Original user input prior to any processing."""

    _model_responses: list[ModelResponse] = field(default_factory=list)
    """Responses from the model so far."""

    _context: RunContextWrapper[TContext] | None = None
    """Run context tracking approvals, usage, and other metadata."""

    _generated_items: list[RunItem] = field(default_factory=list)
    """Items generated by the agent during the run."""

    _max_turns: int = 10
    """Maximum allowed turns before forcing termination."""

    _input_guardrail_results: list[InputGuardrailResult] = field(default_factory=list)
    """Results from input guardrails applied to the run."""

    _output_guardrail_results: list[OutputGuardrailResult] = field(default_factory=list)
    """Results from output guardrails applied to the run."""

    _current_step: NextStepInterruption | None = None
    """Current step if the run is interrupted (e.g., for tool approval)."""

    def __init__(
        self,
        context: RunContextWrapper[TContext],
        original_input: str | list[Any],
        starting_agent: TAgent,
        max_turns: int = 10,
    ):
        """Initialize a new RunState.

        Args:
            context: The run context wrapper.
            original_input: The original input to the agent.
            starting_agent: The agent to start the run with.
            max_turns: Maximum number of turns allowed.
        """
        self._context = context
        self._original_input = original_input
        self._current_agent = starting_agent
        self._max_turns = max_turns
        self._model_responses = []
        self._generated_items = []
        self._input_guardrail_results = []
        self._output_guardrail_results = []
        self._current_step = None
        self._current_turn = 0

    def get_interruptions(self) -> list[RunItem]:
        """Returns all interruptions if the current step is an interruption.

        Returns:
            List of tool approval items awaiting approval, or empty list if no interruptions.
        """
        if self._current_step is None or not isinstance(self._current_step, NextStepInterruption):
            return []
        return self._current_step.interruptions

    def approve(self, approval_item: ToolApprovalItem, always_approve: bool = False) -> None:
        """Approves a tool call requested by the agent through an interruption.

        To approve the request, use this method and then run the agent again with the same state
        object to continue the execution.

        By default it will only approve the current tool call. To allow the tool to be used
        multiple times throughout the run, set `always_approve` to True.

        Args:
            approval_item: The tool call approval item to approve.
            always_approve: If True, always approve this tool (for all future calls).
        """
        if self._context is None:
            raise UserError("Cannot approve tool: RunState has no context")
        self._context.approve_tool(approval_item, always_approve=always_approve)

    def reject(self, approval_item: ToolApprovalItem, always_reject: bool = False) -> None:
        """Rejects a tool call requested by the agent through an interruption.

        To reject the request, use this method and then run the agent again with the same state
        object to continue the execution.

        By default it will only reject the current tool call. To prevent the tool from being
        used throughout the run, set `always_reject` to True.

        Args:
            approval_item: The tool call approval item to reject.
            always_reject: If True, always reject this tool (for all future calls).
        """
        if self._context is None:
            raise UserError("Cannot reject tool: RunState has no context")
        self._context.reject_tool(approval_item, always_reject=always_reject)

    def to_json(self) -> dict[str, Any]:
        """Serializes the run state to a JSON-compatible dictionary.

        This method is used to serialize the run state to a dictionary that can be used to
        resume the run later.

        Returns:
            A dictionary representation of the run state.

        Raises:
            UserError: If required state (agent, context) is missing.
        """
        if self._current_agent is None:
            raise UserError("Cannot serialize RunState: No current agent")
        if self._context is None:
            raise UserError("Cannot serialize RunState: No context")

        # Serialize approval records
        approvals_dict: dict[str, dict[str, Any]] = {}
        for tool_name, record in self._context._approvals.items():
            approvals_dict[tool_name] = {
                "approved": record.approved
                if isinstance(record.approved, bool)
                else list(record.approved),
                "rejected": record.rejected
                if isinstance(record.rejected, bool)
                else list(record.rejected),
            }

        return {
            "$schemaVersion": CURRENT_SCHEMA_VERSION,
            "currentTurn": self._current_turn,
            "currentAgent": {
                "name": self._current_agent.name,
            },
            "originalInput": self._original_input,
            "modelResponses": [
                {
                    "usage": {
                        "requests": resp.usage.requests,
                        "inputTokens": resp.usage.input_tokens,
                        "outputTokens": resp.usage.output_tokens,
                        "totalTokens": resp.usage.total_tokens,
                    },
                    "output": [item.model_dump(exclude_unset=True) for item in resp.output],
                    "responseId": resp.response_id,
                }
                for resp in self._model_responses
            ],
            "context": {
                "usage": {
                    "requests": self._context.usage.requests,
                    "inputTokens": self._context.usage.input_tokens,
                    "outputTokens": self._context.usage.output_tokens,
                    "totalTokens": self._context.usage.total_tokens,
                },
                "approvals": approvals_dict,
                "context": self._context.context
                if hasattr(self._context.context, "__dict__")
                else {},
            },
            "maxTurns": self._max_turns,
            "inputGuardrailResults": [
                {
                    "guardrail": {"type": "input", "name": result.guardrail.name},
                    "output": {
                        "tripwireTriggered": result.output.tripwire_triggered,
                        "outputInfo": result.output.output_info,
                    },
                }
                for result in self._input_guardrail_results
            ],
            "outputGuardrailResults": [
                {
                    "guardrail": {"type": "output", "name": result.guardrail.name},
                    "agentOutput": result.agent_output,
                    "agent": {"name": result.agent.name},
                    "output": {
                        "tripwireTriggered": result.output.tripwire_triggered,
                        "outputInfo": result.output.output_info,
                    },
                }
                for result in self._output_guardrail_results
            ],
            "generatedItems": [self._serialize_item(item) for item in self._generated_items],
            "currentStep": self._serialize_current_step(),
        }

    def _serialize_current_step(self) -> dict[str, Any] | None:
        """Serialize the current step if it's an interruption."""
        if self._current_step is None or not isinstance(self._current_step, NextStepInterruption):
            return None

        return {
            "type": "next_step_interruption",
            "interruptions": [
                {
                    "type": "tool_approval_item",
                    "rawItem": (
                        item.raw_item.model_dump(exclude_unset=True)
                        if hasattr(item.raw_item, "model_dump")
                        else item.raw_item
                    ),
                    "agent": {"name": item.agent.name},
                }
                for item in self._current_step.interruptions
                if isinstance(item, ToolApprovalItem)
            ],
        }

    def _serialize_item(self, item: RunItem) -> dict[str, Any]:
        """Serialize a run item to JSON-compatible dict."""
        # Handle model_dump for Pydantic models, dict conversion for TypedDicts
        raw_item_dict: Any
        if hasattr(item.raw_item, "model_dump"):
            raw_item_dict = item.raw_item.model_dump(exclude_unset=True)  # type: ignore
        elif isinstance(item.raw_item, dict):
            raw_item_dict = dict(item.raw_item)
        else:
            raw_item_dict = item.raw_item

        result: dict[str, Any] = {
            "type": item.type,
            "rawItem": raw_item_dict,
            "agent": {"name": item.agent.name},
        }

        # Add additional fields based on item type
        if hasattr(item, "output"):
            result["output"] = str(item.output)
        if hasattr(item, "source_agent"):
            result["sourceAgent"] = {"name": item.source_agent.name}
        if hasattr(item, "target_agent"):
            result["targetAgent"] = {"name": item.target_agent.name}

        return result

    def to_string(self) -> str:
        """Serializes the run state to a JSON string.

        Returns:
            JSON string representation of the run state.
        """
        return json.dumps(self.to_json(), indent=2)

    @staticmethod
    def from_string(initial_agent: Agent[Any], state_string: str) -> RunState[Any, Agent[Any]]:
        """Deserializes a run state from a JSON string.

        This method is used to deserialize a run state from a string that was serialized using
        the `to_string()` method.

        Args:
            initial_agent: The initial agent (used to build agent map for resolution).
            state_string: The JSON string to deserialize.

        Returns:
            A reconstructed RunState instance.

        Raises:
            UserError: If the string is invalid JSON or has incompatible schema version.
        """
        try:
            state_json = json.loads(state_string)
        except json.JSONDecodeError as e:
            raise UserError(f"Failed to parse run state JSON: {e}") from e

        # Check schema version
        schema_version = state_json.get("$schemaVersion")
        if not schema_version:
            raise UserError("Run state is missing schema version")
        if schema_version != CURRENT_SCHEMA_VERSION:
            raise UserError(
                f"Run state schema version {schema_version} is not supported. "
                f"Please use version {CURRENT_SCHEMA_VERSION}"
            )

        # Build agent map for name resolution
        agent_map = _build_agent_map(initial_agent)

        # Find the current agent
        current_agent_name = state_json["currentAgent"]["name"]
        current_agent = agent_map.get(current_agent_name)
        if not current_agent:
            raise UserError(f"Agent {current_agent_name} not found in agent map")

        # Rebuild context
        context_data = state_json["context"]
        usage = Usage()
        usage.requests = context_data["usage"]["requests"]
        usage.input_tokens = context_data["usage"]["inputTokens"]
        usage.output_tokens = context_data["usage"]["outputTokens"]
        usage.total_tokens = context_data["usage"]["totalTokens"]

        context = RunContextWrapper(context=context_data.get("context", {}))
        context.usage = usage
        context._rebuild_approvals(context_data.get("approvals", {}))

        # Create the RunState instance
        state = RunState(
            context=context,
            original_input=state_json["originalInput"],
            starting_agent=current_agent,
            max_turns=state_json["maxTurns"],
        )

        state._current_turn = state_json["currentTurn"]

        # Reconstruct model responses
        state._model_responses = _deserialize_model_responses(state_json.get("modelResponses", []))

        # Reconstruct generated items
        state._generated_items = _deserialize_items(state_json.get("generatedItems", []), agent_map)

        # Reconstruct guardrail results (simplified - full reconstruction would need more info)
        # For now, we store the basic info
        state._input_guardrail_results = []
        state._output_guardrail_results = []

        # Reconstruct current step if it's an interruption
        current_step_data = state_json.get("currentStep")
        if current_step_data and current_step_data.get("type") == "next_step_interruption":
            from openai.types.responses import ResponseFunctionToolCall

            interruptions: list[RunItem] = []
            for item_data in current_step_data.get("interruptions", []):
                agent_name = item_data["agent"]["name"]
                agent = agent_map.get(agent_name)
                if agent:
                    raw_item = ResponseFunctionToolCall(**item_data["rawItem"])
                    approval_item = ToolApprovalItem(agent=agent, raw_item=raw_item)
                    interruptions.append(approval_item)

            state._current_step = NextStepInterruption(interruptions=interruptions)

        return state

    @staticmethod
    def from_json(
        initial_agent: Agent[Any], state_json: dict[str, Any]
    ) -> RunState[Any, Agent[Any]]:
        """Deserializes a run state from a JSON dictionary.

        This method is used to deserialize a run state from a dict that was created using
        the `to_json()` method.

        Args:
            initial_agent: The initial agent (used to build agent map for resolution).
            state_json: The JSON dictionary to deserialize.

        Returns:
            A reconstructed RunState instance.

        Raises:
            UserError: If the dict has incompatible schema version.
        """
        # Check schema version
        schema_version = state_json.get("$schemaVersion")
        if not schema_version:
            raise UserError("Run state is missing schema version")
        if schema_version != CURRENT_SCHEMA_VERSION:
            raise UserError(
                f"Run state schema version {schema_version} is not supported. "
                f"Please use version {CURRENT_SCHEMA_VERSION}"
            )

        # Build agent map for name resolution
        agent_map = _build_agent_map(initial_agent)

        # Find the current agent
        current_agent_name = state_json["currentAgent"]["name"]
        current_agent = agent_map.get(current_agent_name)
        if not current_agent:
            raise UserError(f"Agent {current_agent_name} not found in agent map")

        # Rebuild context
        context_data = state_json["context"]
        usage = Usage()
        usage.requests = context_data["usage"]["requests"]
        usage.input_tokens = context_data["usage"]["inputTokens"]
        usage.output_tokens = context_data["usage"]["outputTokens"]
        usage.total_tokens = context_data["usage"]["totalTokens"]

        context = RunContextWrapper(context=context_data.get("context", {}))
        context.usage = usage
        context._rebuild_approvals(context_data.get("approvals", {}))

        # Create the RunState instance
        state = RunState(
            context=context,
            original_input=state_json["originalInput"],
            starting_agent=current_agent,
            max_turns=state_json["maxTurns"],
        )

        state._current_turn = state_json["currentTurn"]

        # Reconstruct model responses
        state._model_responses = _deserialize_model_responses(state_json.get("modelResponses", []))

        # Reconstruct generated items
        state._generated_items = _deserialize_items(state_json.get("generatedItems", []), agent_map)

        # Reconstruct guardrail results (simplified - full reconstruction would need more info)
        # For now, we store the basic info
        state._input_guardrail_results = []
        state._output_guardrail_results = []

        # Reconstruct current step if it's an interruption
        current_step_data = state_json.get("currentStep")
        if current_step_data and current_step_data.get("type") == "next_step_interruption":
            from openai.types.responses import ResponseFunctionToolCall

            interruptions: list[RunItem] = []
            for item_data in current_step_data.get("interruptions", []):
                agent_name = item_data["agent"]["name"]
                agent = agent_map.get(agent_name)
                if agent:
                    raw_item = ResponseFunctionToolCall(**item_data["rawItem"])
                    approval_item = ToolApprovalItem(agent=agent, raw_item=raw_item)
                    interruptions.append(approval_item)

            state._current_step = NextStepInterruption(interruptions=interruptions)

        return state


def _build_agent_map(initial_agent: Agent[Any]) -> dict[str, Agent[Any]]:
    """Build a map of agent names to agents by traversing handoffs.

    Args:
        initial_agent: The starting agent.

    Returns:
        Dictionary mapping agent names to agent instances.
    """
    agent_map: dict[str, Agent[Any]] = {}
    queue = [initial_agent]

    while queue:
        current = queue.pop(0)
        if current.name in agent_map:
            continue
        agent_map[current.name] = current

        # Add handoff agents to the queue
        for handoff in current.handoffs:
            if hasattr(handoff, "agent") and handoff.agent:
                if handoff.agent.name not in agent_map:
                    queue.append(handoff.agent)

    return agent_map


def _deserialize_model_responses(responses_data: list[dict[str, Any]]) -> list[ModelResponse]:
    """Deserialize model responses from JSON data.

    Args:
        responses_data: List of serialized model response dictionaries.

    Returns:
        List of ModelResponse instances.
    """

    from .items import ModelResponse

    result = []
    for resp_data in responses_data:
        usage = Usage()
        usage.requests = resp_data["usage"]["requests"]
        usage.input_tokens = resp_data["usage"]["inputTokens"]
        usage.output_tokens = resp_data["usage"]["outputTokens"]
        usage.total_tokens = resp_data["usage"]["totalTokens"]

        from pydantic import TypeAdapter

        output_adapter: TypeAdapter[Any] = TypeAdapter(list[Any])
        output = output_adapter.validate_python(resp_data["output"])

        result.append(
            ModelResponse(
                usage=usage,
                output=output,
                response_id=resp_data.get("responseId"),
            )
        )

    return result


def _deserialize_items(
    items_data: list[dict[str, Any]], agent_map: dict[str, Agent[Any]]
) -> list[RunItem]:
    """Deserialize run items from JSON data.

    Args:
        items_data: List of serialized run item dictionaries.
        agent_map: Map of agent names to agent instances.

    Returns:
        List of RunItem instances.
    """
    from openai.types.responses import (
        ResponseFunctionToolCall,
        ResponseOutputMessage,
        ResponseReasoningItem,
    )
    from openai.types.responses.response_output_item import (
        McpApprovalRequest,
        McpListTools,
    )

    from .items import (
        HandoffCallItem,
        HandoffOutputItem,
        MCPApprovalRequestItem,
        MCPApprovalResponseItem,
        MCPListToolsItem,
        MessageOutputItem,
        ReasoningItem,
        ToolApprovalItem,
        ToolCallItem,
        ToolCallOutputItem,
    )

    result: list[RunItem] = []

    for item_data in items_data:
        item_type = item_data["type"]
        agent_name = item_data["agent"]["name"]
        agent = agent_map.get(agent_name)
        if not agent:
            logger.warning(f"Agent {agent_name} not found, skipping item")
            continue

        raw_item_data = item_data["rawItem"]

        try:
            if item_type == "message_output_item":
                raw_item_msg = ResponseOutputMessage(**raw_item_data)
                result.append(MessageOutputItem(agent=agent, raw_item=raw_item_msg))

            elif item_type == "tool_call_item":
                raw_item_tool = ResponseFunctionToolCall(**raw_item_data)
                result.append(ToolCallItem(agent=agent, raw_item=raw_item_tool))

            elif item_type == "tool_call_output_item":
                # For tool call outputs, we use the raw dict as TypedDict
                result.append(
                    ToolCallOutputItem(
                        agent=agent,
                        raw_item=raw_item_data,
                        output=item_data.get("output", ""),
                    )
                )

            elif item_type == "reasoning_item":
                raw_item_reason = ResponseReasoningItem(**raw_item_data)
                result.append(ReasoningItem(agent=agent, raw_item=raw_item_reason))

            elif item_type == "handoff_call_item":
                raw_item_handoff = ResponseFunctionToolCall(**raw_item_data)
                result.append(HandoffCallItem(agent=agent, raw_item=raw_item_handoff))

            elif item_type == "handoff_output_item":
                source_agent = agent_map.get(item_data["sourceAgent"]["name"])
                target_agent = agent_map.get(item_data["targetAgent"]["name"])
                if source_agent and target_agent:
                    result.append(
                        HandoffOutputItem(
                            agent=agent,
                            raw_item=raw_item_data,
                            source_agent=source_agent,
                            target_agent=target_agent,
                        )
                    )

            elif item_type == "mcp_list_tools_item":
                raw_item_mcp_list = McpListTools(**raw_item_data)
                result.append(MCPListToolsItem(agent=agent, raw_item=raw_item_mcp_list))

            elif item_type == "mcp_approval_request_item":
                raw_item_mcp_req = McpApprovalRequest(**raw_item_data)
                result.append(MCPApprovalRequestItem(agent=agent, raw_item=raw_item_mcp_req))

            elif item_type == "mcp_approval_response_item":
                # Use raw dict for TypedDict
                result.append(MCPApprovalResponseItem(agent=agent, raw_item=raw_item_data))

            elif item_type == "tool_approval_item":
                raw_item_approval = ResponseFunctionToolCall(**raw_item_data)
                result.append(ToolApprovalItem(agent=agent, raw_item=raw_item_approval))

        except Exception as e:
            logger.warning(f"Failed to deserialize item of type {item_type}: {e}")
            continue

    return result
