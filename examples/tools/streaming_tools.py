"""
@streaming_tool æƒå¨ä½¿ç”¨ç¤ºä¾‹é›†

æœ¬æ–‡ä»¶å±•ç¤ºäº† @streaming_tool è£…é¥°å™¨çš„å„ç§æ ¸å¿ƒä½¿ç”¨åœºæ™¯ï¼ŒåŒ…æ‹¬ï¼š
1. å¤šé˜¶æ®µè¿›åº¦æ›´æ–°
2. æ‰“å­—æœºæ•ˆæœï¼ˆå¢é‡è¾“å‡ºï¼‰
3. é«˜çº§æµç¨‹ç¼–æ’ï¼ˆAgent as Toolï¼‰
4. é”™è¯¯å¤„ç†ä¸æ‹¬å·äº‹ä»¶

è®¾è®¡å“²å­¦ï¼šä¸¥æ ¼åˆ†ç¦»"è¿‡ç¨‹å±•ç¤º"ä¸"æœ€ç»ˆç»“æœ"
- è¿‡ç¨‹å±•ç¤ºï¼šyield NotifyStreamEvent(...) - ä¸å½±å“å¯¹è¯å†å²
- æœ€ç»ˆç»“æœï¼šyield "å­—ç¬¦ä¸²ç»“æœ" - ä½œä¸ºæœ€åä¸€ä¸ªyieldï¼Œå½±å“å¯¹è¯å†å²
"""
import asyncio
from collections.abc import AsyncGenerator
from typing import Any, Union

from agents import Agent, NotifyStreamEvent, Runner, StreamEvent, streaming_tool

# ============================================================================
# åœºæ™¯ä¸€ï¼šå¤šé˜¶æ®µè¿›åº¦æ›´æ–°
# æ ¸å¿ƒæ¨¡å¼ï¼šyield NotifyStreamEvent(...) ç”¨äºè¿‡ç¨‹å±•ç¤º
# ============================================================================

@streaming_tool
async def data_pipeline_tool(source_url: str, batch_size: int = 100) -> AsyncGenerator[StreamEvent | str, Any]:
    """æ•°æ®ç®¡é“å¤„ç†å·¥å…· - æ¼”ç¤ºå¤šé˜¶æ®µè¿›åº¦æ›´æ–°

    è¿™ä¸ªå·¥å…·å±•ç¤ºäº†å¦‚ä½•åœ¨é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ä¸­æä¾›è¯¦ç»†çš„è¿›åº¦åé¦ˆã€‚
    æ¯ä¸ª NotifyStreamEvent éƒ½æ˜¯çº¯å±•ç¤ºæ€§è´¨ï¼Œä¸ä¼šå½±å“å¯¹è¯å†å²ã€‚

    Args:
        source_url: æ•°æ®æºURL
        batch_size: æ‰¹å¤„ç†å¤§å°
    """
    # é˜¶æ®µ1ï¼šè¿æ¥
    yield NotifyStreamEvent(data=f"[1/4] æ­£åœ¨è¿æ¥åˆ°æ•°æ®æº: {source_url}")
    await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ

    # é˜¶æ®µ2ï¼šä¸‹è½½ï¼ˆå¸¦æˆåŠŸæ ‡ç­¾ï¼‰
    yield NotifyStreamEvent(data="[2/4] âœ… è¿æ¥æˆåŠŸï¼Œå¼€å§‹ä¸‹è½½æ•°æ®...", tag="success")
    await asyncio.sleep(0.3)

    # é˜¶æ®µ3ï¼šæ‰¹å¤„ç†è¿›åº¦ï¼ˆæ¼”ç¤ºåŠ¨æ€è¿›åº¦æ›´æ–°ï¼‰
    total_records = 1234
    processed = 0

    while processed < total_records:
        batch_end = min(processed + batch_size, total_records)
        yield NotifyStreamEvent(
            data=f"[3/4] å¤„ç†è®°å½• {processed + 1}-{batch_end}/{total_records}",
            tag="progress"
        )
        processed = batch_end
        await asyncio.sleep(0.1)

    # é˜¶æ®µ4ï¼šæœ€ç»ˆå¤„ç†
    yield NotifyStreamEvent(data="[4/4] æ•°æ®éªŒè¯å’Œæ¸…ç†ä¸­...", tag="processing")
    await asyncio.sleep(0.2)

    yield NotifyStreamEvent(data="ğŸ‰ å¤„ç†å®Œæˆ!", tag="success")

    # å…³é”®ï¼šæœ€ç»ˆç»“æœå¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼Œä¸”ä½œä¸ºæœ€åä¸€ä¸ªyield
    yield f"æ•°æ®ç®¡é“å¤„ç†æˆåŠŸï¼ä» {source_url} å¤„ç†äº† {total_records} æ¡è®°å½•ï¼Œæ‰¹å¤§å°: {batch_size}"


# ============================================================================
# åœºæ™¯äºŒï¼šRAGæ‰“å­—æœºæ•ˆæœï¼ˆå¢é‡è¾“å‡ºï¼‰
# æ ¸å¿ƒæ¨¡å¼ï¼šis_delta=True ç”¨äºæµå¼æ–‡æœ¬è¾“å‡º
# ============================================================================

@streaming_tool
async def research_and_summarize_tool(topic: str) -> AsyncGenerator[StreamEvent | str, Any]:
    """RAGç ”ç©¶æ€»ç»“å·¥å…· - æ¼”ç¤ºæ‰“å­—æœºæ•ˆæœçš„å®é™…åº”ç”¨

    è¿™ä¸ªå·¥å…·æ¨¡æ‹Ÿäº†ä¸€ä¸ªçœŸå®çš„RAGåœºæ™¯ï¼šæ£€ç´¢æ–‡æ¡£ -> ç”Ÿæˆæ€»ç»“ -> æµå¼è¾“å‡º
    å±•ç¤ºäº†å¦‚ä½•ç»“åˆè¿›åº¦é€šçŸ¥å’Œå¢é‡æ–‡æœ¬è¾“å‡ºã€‚

    Args:
        topic: ç ”ç©¶ä¸»é¢˜
    """
    # ç¬¬ä¸€é˜¶æ®µï¼šæ£€ç´¢
    yield NotifyStreamEvent(data=f"ğŸ” æ­£åœ¨æ£€ç´¢å…³äº'{topic}'çš„æ–‡æ¡£...")
    await asyncio.sleep(0.8)  # æ¨¡æ‹Ÿæ£€ç´¢æ—¶é—´

    # æ¨¡æ‹Ÿæ£€ç´¢ç»“æœ
    documents_found = 15
    yield NotifyStreamEvent(data=f"âœ… æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {documents_found} ä¸ªç›¸å…³æ–‡æ¡£", tag="success")

    # ç¬¬äºŒé˜¶æ®µï¼šåˆ†æ
    yield NotifyStreamEvent(data="ğŸ§  æ­£åœ¨åˆ†ææ–‡æ¡£å†…å®¹ï¼Œç”Ÿæˆæ€»ç»“...")
    await asyncio.sleep(0.5)

    # ç¬¬ä¸‰é˜¶æ®µï¼šæµå¼è¾“å‡ºæ€»ç»“ï¼ˆæ‰“å­—æœºæ•ˆæœï¼‰
    yield NotifyStreamEvent(data="ğŸ“ å¼€å§‹è¾“å‡ºæ€»ç»“ï¼š", tag="output_start")

    # æ¨¡æ‹ŸLLMæµå¼è¾“å‡º
    summary_parts = [
        f"å…³äº{topic}çš„ç ”ç©¶æ€»ç»“ï¼š\n\n",
        "1. æ ¸å¿ƒæ¦‚å¿µï¼š",
        f"{topic}æ˜¯ä¸€ä¸ªé‡è¦çš„æŠ€æœ¯é¢†åŸŸï¼Œ",
        "å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚\n\n",
        "2. ä¸»è¦ç‰¹ç‚¹ï¼š\n",
        "- é«˜æ•ˆæ€§èƒ½\n",
        "- æ˜“äºæ‰©å±•\n",
        "- ç¤¾åŒºæ´»è·ƒ\n\n",
        "3. åº”ç”¨åœºæ™¯ï¼š\n",
        "åœ¨å¤šä¸ªè¡Œä¸šä¸­éƒ½æœ‰æˆåŠŸæ¡ˆä¾‹ï¼Œ",
        "ç‰¹åˆ«æ˜¯åœ¨æ•°æ®å¤„ç†å’Œè‡ªåŠ¨åŒ–é¢†åŸŸã€‚\n\n",
        "æ€»ç»“å®Œæˆã€‚"
    ]

    full_summary = ""
    for part in summary_parts:
        full_summary += part
        # å…³é”®ï¼šä½¿ç”¨ is_delta=True å®ç°æ‰“å­—æœºæ•ˆæœ
        yield NotifyStreamEvent(data=part, is_delta=True, tag="typewriter")
        await asyncio.sleep(0.1)  # æ§åˆ¶æ‰“å­—é€Ÿåº¦

    yield NotifyStreamEvent(data="âœ… æ€»ç»“ç”Ÿæˆå®Œæˆ", tag="complete")

    # æœ€ç»ˆç»“æœï¼šå®Œæ•´çš„æ€»ç»“æ–‡æœ¬
    yield full_summary


@streaming_tool
async def simple_typewriter_tool(text: str, speed: float = 0.05) -> AsyncGenerator[StreamEvent | str, Any]:
    """ç®€å•æ‰“å­—æœºå·¥å…· - åŸºç¡€çš„å­—ç¬¦çº§å¢é‡è¾“å‡º

    Args:
        text: è¦æ˜¾ç¤ºçš„æ–‡æœ¬
        speed: æ‰“å­—é€Ÿåº¦ï¼ˆç§’/å­—ç¬¦ï¼‰
    """
    yield NotifyStreamEvent(data="å¼€å§‹æ‰“å­—æœºè¾“å‡º...", tag="start")

    full_text = ""
    for char in text:
        full_text += char
        # ä½¿ç”¨ is_delta=True è¡¨ç¤ºè¿™æ˜¯å¢é‡æ›´æ–°
        yield NotifyStreamEvent(data=char, is_delta=True, tag="typewriter")
        await asyncio.sleep(speed)

    yield NotifyStreamEvent(data="\nâœ… è¾“å‡ºå®Œæˆ", tag="complete")
    yield f"æ‰“å­—æœºè¾“å‡ºå®Œæˆ: '{full_text}'"


# ============================================================================
# åœºæ™¯ä¸‰ï¼šé«˜çº§æµç¨‹ç¼–æ’ - Agent as Tool
# æ ¸å¿ƒæ¨¡å¼ï¼šAgent.as_tool(streaming=True) å®ç°æ— ç¼åµŒå¥—
# ============================================================================

# é¦–å…ˆå®šä¹‰ä¸€ä¸ªä¸“é—¨çš„æ–‡ä»¶åˆ†æå­Agent
def create_file_analysis_agent():
    """åˆ›å»ºä¸“é—¨çš„æ–‡ä»¶åˆ†æAgent"""

    @streaming_tool
    async def analyze_content_tool(content_type: str) -> AsyncGenerator[StreamEvent | str, Any]:
        """å†…å®¹åˆ†æå·¥å…·"""
        yield NotifyStreamEvent(data=f"ğŸ” å¼€å§‹{content_type}åˆ†æ...")
        await asyncio.sleep(0.3)

        analysis_steps = [
            "è¯æ±‡ç»Ÿè®¡", "è¯­æ³•æ£€æŸ¥", "å…³é”®è¯æå–", "æƒ…æ„Ÿåˆ†æ"
        ]

        for i, step in enumerate(analysis_steps, 1):
            yield NotifyStreamEvent(data=f"[{i}/{len(analysis_steps)}] {step}ä¸­...", tag="progress")
            await asyncio.sleep(0.2)

        yield f"{content_type}åˆ†æå®Œæˆï¼šå‘ç° 1,234 ä¸ªè¯æ±‡ï¼Œæƒ…æ„Ÿå€¾å‘ä¸ºç§¯æ"

    return Agent(
        name="FileAnalysisAgent",
        instructions="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡ä»¶åˆ†æä¸“å®¶ã€‚ä½¿ç”¨analyze_content_toolæ¥åˆ†æä¸åŒç±»å‹çš„å†…å®¹ã€‚",
        tools=[analyze_content_tool]
    )


# åˆ›å»ºä½¿ç”¨å­Agentçš„ä¸»ç¼–æ’Agent
def create_orchestrator_agent():
    """åˆ›å»ºç¼–æ’Agentï¼Œæ¼”ç¤ºAgent as Toolçš„å¼ºå¤§åŠŸèƒ½"""

    # åˆ›å»ºä¸“é—¨çš„å­Agent
    file_analysis_agent = create_file_analysis_agent()

    # å°†å­AgentåŒ…è£…æˆæµå¼å·¥å…·
    return Agent(
        name="DocumentProcessorAgent",
        instructions="""ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£å¤„ç†ç¼–æ’å™¨ã€‚å½“ç”¨æˆ·è¦æ±‚åˆ†ææ–‡ä»¶æ—¶ï¼š
1. ä½¿ç”¨ run_file_analysis å·¥å…·è°ƒç”¨ä¸“é—¨çš„åˆ†æAgent
2. è§£é‡Šåˆ†æç»“æœå¹¶æä¾›å»ºè®®""",
        tools=[
            file_analysis_agent.as_tool(
                tool_name="run_file_analysis",
                tool_description="è¿è¡Œä¸“é—¨çš„æ–‡ä»¶åˆ†æAgent",
                streaming=True,  # å…³é”®ï¼šå¯ç”¨æµå¼è¾“å‡º
                enable_bracketing=True  # æ¨èï¼šæä¾›æ¸…æ™°çš„åµŒå¥—å±‚æ¬¡
            )
        ]
    )


# ä¼ ç»Ÿçš„å•ä¸€å·¥å…·å®ç°ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
@streaming_tool
async def traditional_file_analyzer(file_path: str) -> AsyncGenerator[StreamEvent | str, Any]:
    """ä¼ ç»Ÿçš„æ–‡ä»¶åˆ†æå·¥å…· - ç”¨äºä¸Agent as Toolæ–¹æ¡ˆå¯¹æ¯”

    Args:
        file_path: è¦åˆ†æçš„æ–‡ä»¶è·¯å¾„
    """
    yield NotifyStreamEvent(data=f"å¼€å§‹åˆ†ææ–‡ä»¶: {file_path}")

    # æ¨¡æ‹Ÿæ–‡ä»¶è¯»å–
    yield NotifyStreamEvent(data="ğŸ“– è¯»å–æ–‡ä»¶å†…å®¹...", tag="reading")
    await asyncio.sleep(0.3)

    # æ¨¡æ‹Ÿå„ç§åˆ†ææ­¥éª¤
    analysis_steps = [
        ("ğŸ” è¯æ±‡åˆ†æ", "analyzing"),
        ("ğŸ“Š ç»Ÿè®¡è®¡ç®—", "calculating"),
        ("ğŸ¯ å…³é”®è¯æå–", "extracting"),
        ("ğŸ“ˆ ç”ŸæˆæŠ¥å‘Š", "reporting")
    ]

    results: dict[str, Union[int, float, list[str]]] = {}
    for step_name, tag in analysis_steps:
        yield NotifyStreamEvent(data=step_name, tag=tag)
        await asyncio.sleep(0.4)

        # æ¨¡æ‹Ÿåˆ†æç»“æœ
        if "è¯æ±‡" in step_name:
            results["word_count"] = 1542
        elif "ç»Ÿè®¡" in step_name:
            results["avg_sentence_length"] = 12.3
        elif "å…³é”®è¯" in step_name:
            results["keywords"] = ["Python", "AI", "å·¥å…·", "æµå¼"]

    yield NotifyStreamEvent(data="âœ… åˆ†æå®Œæˆ!", tag="success")

    # è¿”å›åˆ†æç»“æœ
    keywords = results['keywords']
    assert isinstance(keywords, list), "keywords should be a list"
    yield f"""æ–‡ä»¶åˆ†æå®Œæˆ: {file_path}
ğŸ“Š ç»Ÿè®¡ç»“æœ:
- è¯æ±‡æ•°é‡: {results['word_count']}
- å¹³å‡å¥é•¿: {results['avg_sentence_length']}
- å…³é”®è¯: {', '.join(keywords)}"""


# ============================================================================
# åœºæ™¯å››ï¼šæ‹¬å·äº‹ä»¶æ¼”ç¤º - æ¸…æ™°çš„æµç¨‹è¾¹ç•Œ
# æ ¸å¿ƒæ¨¡å¼ï¼šenable_bracketing=True æä¾›åµŒå¥—ä¸Šä¸‹æ–‡
# ============================================================================

@streaming_tool(enable_bracketing=True)
async def complex_workflow_tool(task_name: str) -> AsyncGenerator[StreamEvent | str, Any]:
    """å¤æ‚å·¥ä½œæµå·¥å…· - æ¼”ç¤ºæ‹¬å·äº‹ä»¶çš„é‡è¦æ€§

    enable_bracketing=True ä¼šè‡ªåŠ¨ç”Ÿæˆ ToolStreamStartEvent å’Œ ToolStreamEndEventï¼Œ
    ä¸ºå®¢æˆ·ç«¯æä¾›æ¸…æ™°çš„æµç¨‹è¾¹ç•Œï¼Œç‰¹åˆ«é€‚ç”¨äºåµŒå¥—è°ƒç”¨åœºæ™¯ã€‚

    Args:
        task_name: ä»»åŠ¡åç§°
    """
    yield NotifyStreamEvent(data=f"ğŸš€ å¯åŠ¨å¤æ‚å·¥ä½œæµ: {task_name}")

    # æ¨¡æ‹Ÿå¤šä¸ªå­ä»»åŠ¡
    subtasks = ["ç¯å¢ƒåˆå§‹åŒ–", "æ•°æ®æ”¶é›†", "æ ¸å¿ƒå¤„ç†", "ç»“æœéªŒè¯", "æ¸…ç†å·¥ä½œ"]

    for i, subtask in enumerate(subtasks, 1):
        yield NotifyStreamEvent(
            data=f"[{i}/{len(subtasks)}] {subtask}ä¸­...",
            tag="workflow"
        )
        await asyncio.sleep(0.3)

        if subtask == "æ ¸å¿ƒå¤„ç†":
            # åœ¨æ ¸å¿ƒå¤„ç†æ­¥éª¤ä¸­æ·»åŠ æ›´è¯¦ç»†çš„è¿›åº¦
            for j in range(1, 4):
                yield NotifyStreamEvent(
                    data=f"  â””â”€ å¤„ç†é˜¶æ®µ {j}/3: æ­£åœ¨ä¼˜åŒ–ç®—æ³•å‚æ•°",
                    tag="subprocess"
                )
                await asyncio.sleep(0.2)

    yield NotifyStreamEvent(data="âœ… æ‰€æœ‰æ­¥éª¤å®Œæˆ!", tag="success")

    # æ³¨æ„ï¼šToolStreamEndEvent ä¼šåœ¨è¿™ä¸ª yield ä¹‹å‰è‡ªåŠ¨å‘é€
    yield f"å·¥ä½œæµ '{task_name}' æ‰§è¡Œå®Œæˆï¼æ‰€æœ‰ {len(subtasks)} ä¸ªæ­¥éª¤å·²æˆåŠŸå®Œæˆï¼Œè€—æ—¶çº¦ {len(subtasks) * 0.3:.1f} ç§’ã€‚"


# ============================================================================
# æ¼”ç¤ºç”¨çš„Agenté…ç½®
# ============================================================================

def create_demo_agent():
    """åˆ›å»ºæ¼”ç¤ºç”¨çš„Agentï¼Œé›†æˆæ‰€æœ‰æµå¼å·¥å…·"""
    return Agent(
        name="StreamingToolDemoAgent",
        instructions="""ä½ æ˜¯ä¸€ä¸ª@streaming_toolåŠŸèƒ½æ¼”ç¤ºä¸“å®¶ã€‚ä½ æ‹¥æœ‰ä»¥ä¸‹èƒ½åŠ›ï¼š

1. data_pipeline_tool - æ¼”ç¤ºå¤šé˜¶æ®µè¿›åº¦æ›´æ–°
2. research_and_summarize_tool - æ¼”ç¤ºRAGåœºæ™¯çš„æ‰“å­—æœºæ•ˆæœ
3. simple_typewriter_tool - æ¼”ç¤ºåŸºç¡€çš„å­—ç¬¦çº§å¢é‡è¾“å‡º
4. traditional_file_analyzer - æ¼”ç¤ºä¼ ç»Ÿçš„å•ä¸€å·¥å…·æ–¹æ¡ˆ
5. complex_workflow_tool - æ¼”ç¤ºæ‹¬å·äº‹ä»¶çš„é‡è¦æ€§

å½“ç”¨æˆ·è¯·æ±‚æ¼”ç¤ºæ—¶ï¼Œé€‰æ‹©æœ€åˆé€‚çš„å·¥å…·å¹¶è¯¦ç»†è§£é‡Šæ¯ä¸ªäº‹ä»¶çš„å«ä¹‰ã€‚""",
        tools=[
            data_pipeline_tool,
            research_and_summarize_tool,
            simple_typewriter_tool,
            traditional_file_analyzer,
            complex_workflow_tool
        ],
    )


# ============================================================================
# æ ¸å¿ƒæ¼”ç¤ºå‡½æ•°
# ============================================================================

async def demo_core_scenarios():
    """æ¼”ç¤º@streaming_toolçš„æ ¸å¿ƒä½¿ç”¨åœºæ™¯"""
    print("=" * 80)
    print("@streaming_tool æƒå¨ä½¿ç”¨æ¼”ç¤º")
    print("è®¾è®¡å“²å­¦ï¼šä¸¥æ ¼åˆ†ç¦»'è¿‡ç¨‹å±•ç¤º'ä¸'æœ€ç»ˆç»“æœ'")
    print("=" * 80)

    demo_agent = create_demo_agent()

    scenarios = [
        {
            "name": "åœºæ™¯ä¸€ï¼šå¤šé˜¶æ®µè¿›åº¦æ›´æ–°",
            "input": "è¯·å¤„ç†æ¥è‡ª https://api.example.com/data çš„æ•°æ®ï¼Œæ‰¹å¤§å°è®¾ä¸º50",
            "description": "æ¼”ç¤ºå¦‚ä½•åœ¨é•¿æ—¶é—´ä»»åŠ¡ä¸­æä¾›è¯¦ç»†çš„é˜¶æ®µæ€§è¿›åº¦åé¦ˆ"
        },
        {
            "name": "åœºæ™¯äºŒï¼šRAGæ‰“å­—æœºæ•ˆæœ",
            "input": "è¯·ç ”ç©¶å¹¶æ€»ç»“'äººå·¥æ™ºèƒ½'è¿™ä¸ªä¸»é¢˜",
            "description": "æ¼”ç¤ºæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)åœºæ™¯ä¸­çš„æµå¼æ–‡æœ¬è¾“å‡º"
        },
        {
            "name": "åœºæ™¯ä¸‰ï¼šæ‹¬å·äº‹ä»¶æ¼”ç¤º",
            "input": "æ‰§è¡Œåä¸º'æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ'çš„å¤æ‚å·¥ä½œæµ",
            "description": "æ¼”ç¤ºenable_bracketing=Trueå¦‚ä½•æä¾›æ¸…æ™°çš„æµç¨‹è¾¹ç•Œ"
        }
    ]

    for i, scenario in enumerate(scenarios, 1):
        print(f"\n{'-' * 60}")
        print(f"{scenario['name']}")
        print(f"è¯´æ˜: {scenario['description']}")
        print(f"ç”¨æˆ·è¾“å…¥: {scenario['input']}")
        print(f"{'-' * 60}")
        print("æµå¼äº‹ä»¶åºåˆ—:")

        result = Runner.run_streamed(demo_agent, input=scenario['input'])

        event_count = 0
        async for event in result.stream_events():
            event_count += 1

            if event.type == "notify_stream_event":
                # æ ¹æ®æ ‡ç­¾å’Œç±»å‹æ˜¾ç¤ºä¸åŒæ ¼å¼
                if event.tag == "success":
                    print(f"  [{event_count:2d}] âœ… {event.data}")
                elif event.tag == "error":
                    print(f"  [{event_count:2d}] âŒ {event.data}")
                elif event.tag == "progress":
                    print(f"  [{event_count:2d}] ğŸ“Š {event.data}")
                elif event.tag == "typewriter" and event.is_delta:
                    print(event.data, end="", flush=True)
                elif event.tag == "workflow":
                    print(f"  [{event_count:2d}] ğŸ”„ {event.data}")
                else:
                    print(f"  [{event_count:2d}] ğŸ“ {event.data}")
            elif event.type == "tool_stream_start_event":
                print(f"  [{event_count:2d}] ğŸš€ [å¼€å§‹] {event.tool_name}")
            elif event.type == "tool_stream_end_event":
                print(f"  [{event_count:2d}] ğŸ [ç»“æŸ] {event.tool_name}")

        print(f"\nğŸ’¡ æœ€ç»ˆç»“æœ: {result.final_output}")
        print(f"ğŸ“Š æ€»äº‹ä»¶æ•°: {event_count}")

        if i < len(scenarios):
            print("\n" + "=" * 80)


async def demo_agent_as_tool():
    """æ¼”ç¤ºAgent as Toolçš„å¼ºå¤§åŠŸèƒ½"""
    print("\n" + "=" * 80)
    print("é«˜çº§åœºæ™¯ï¼šAgent as Tool - æ— ç¼æµç¨‹ç¼–æ’")
    print("æ ¸å¿ƒä¼˜åŠ¿ï¼šAgent.as_tool(streaming=True) å®ç°é›¶ä»£ç åµŒå¥—")
    print("=" * 80)

    # åˆ›å»ºç¼–æ’Agent
    orchestrator = create_orchestrator_agent()

    print("ç”¨æˆ·è¾“å…¥: è¯·åˆ†æä¸€ä¸ªPythonä»£ç æ–‡ä»¶çš„å†…å®¹")
    print("-" * 60)
    print("åµŒå¥—äº‹ä»¶æµï¼ˆæ³¨æ„å±‚æ¬¡ç»“æ„ï¼‰:")

    result = Runner.run_streamed(orchestrator, input="è¯·åˆ†æä¸€ä¸ªPythonä»£ç æ–‡ä»¶çš„å†…å®¹")

    event_count = 0
    indent_level = 0

    async for event in result.stream_events():
        event_count += 1
        indent = "  " * indent_level

        if event.type == "tool_stream_start_event":
            print(f"{indent}[{event_count:2d}] ğŸš€ å¼€å§‹è°ƒç”¨: {event.tool_name}")
            if event.tool_name == "run_file_analysis":
                indent_level += 1
        elif event.type == "tool_stream_end_event":
            if hasattr(event, 'tool_name') and event.tool_name == "run_file_analysis":
                indent_level = max(0, indent_level - 1)
            print(f"{indent}[{event_count:2d}] ğŸ ç»“æŸè°ƒç”¨: {event.tool_name}")
        elif event.type == "notify_stream_event":
            if event.tag == "progress":
                print(f"{indent}[{event_count:2d}] ğŸ“Š {event.data}")
            else:
                print(f"{indent}[{event_count:2d}] ğŸ“ {event.data}")

    print(f"\nğŸ’¡ ç¼–æ’ç»“æœ: {result.final_output}")
    print(f"ğŸ“Š æ€»äº‹ä»¶æ•°: {event_count}")
    print("\nğŸ¯ å…³é”®è§‚å¯Ÿï¼šå­Agentçš„æ‰€æœ‰äº‹ä»¶éƒ½è¢«è‡ªåŠ¨è½¬å‘åˆ°ä¸»æµä¸­ï¼")


async def demo_direct_tool_calls():
    """æ¼”ç¤ºç›´æ¥è°ƒç”¨æµå¼å·¥å…·ï¼ˆä¸é€šè¿‡Agentï¼‰"""
    print("\n" + "=" * 80)
    print("åº•å±‚æ¼”ç¤ºï¼šç›´æ¥è°ƒç”¨æµå¼å·¥å…·")
    print("é€‚ç”¨åœºæ™¯ï¼šæµ‹è¯•ã€è°ƒè¯•æˆ–è‡ªå®šä¹‰é›†æˆ")
    print("=" * 80)

    from agents.run_context import RunContextWrapper

    ctx = RunContextWrapper(context=None)

    print("ç›´æ¥è°ƒç”¨ data_pipeline_tool:")
    print("-" * 40)

    event_count = 0
    async for event in data_pipeline_tool.on_invoke_tool(
        ctx,
        '{"source_url": "https://example.com/api", "batch_size": 50}',
        "direct_demo_call"
    ):
        event_count += 1
        if isinstance(event, NotifyStreamEvent):
            tag_info = f" (æ ‡ç­¾: {event.tag})" if event.tag else ""
            print(f"  [{event_count}] äº‹ä»¶: {event.data}{tag_info}")
        elif isinstance(event, str):
            print(f"  [{event_count}] æœ€ç»ˆç»“æœ: {event}")

    print(f"\nğŸ“Š ç›´æ¥è°ƒç”¨äº‹ä»¶æ•°: {event_count}")


async def demo_quick_reference():
    """å¿«é€Ÿå‚è€ƒï¼šå¼€å‘è€…æ„å›¾ä¸ä»£ç æ˜ å°„"""
    print("\n" + "=" * 80)
    print("å¿«é€Ÿå‚è€ƒï¼š@streaming_tool å¼€å‘è€…æ„å›¾æ˜ å°„è¡¨")
    print("=" * 80)

    reference_table = [
        ("æŠ¥å‘Šå®Œæ•´çš„è¿›åº¦æ­¥éª¤", "yield NotifyStreamEvent(data='...')", "å¦"),
        ("æµå¼è¾“å‡ºæ–‡æœ¬(æ‰“å­—æœº)", "yield NotifyStreamEvent(data='...', is_delta=True)", "å¦"),
        ("æ ‡è®°ç‰¹æ®Šäº‹ä»¶ç±»å‹", "yield NotifyStreamEvent(data='...', tag='success')", "å¦"),
        ("æä¾›å·¥å…·æœ€ç»ˆç»“æœ", "yield 'æœ€ç»ˆçš„å­—ç¬¦ä¸²ç»“æœ' (ä½œä¸ºæœ€åä¸€ä¸ªyield)", "æ˜¯"),
        ("å¯ç”¨æµç¨‹æ‹¬å·äº‹ä»¶", "@streaming_tool(enable_bracketing=True)", "å¦"),
        ("Agentä½œä¸ºæµå¼å·¥å…·", "agent.as_tool(streaming=True)", "æ˜¯(ç”±å­æµç¨‹å†³å®š)")
    ]

    print(f"{'å¼€å‘è€…æ„å›¾':<20} {'åº”ç¼–å†™çš„ä»£ç ':<45} {'å½±å“å¯¹è¯å†å²?'}")
    print("-" * 80)
    for intent, code, affects_history in reference_table:
        print(f"{intent:<20} {code:<45} {affects_history}")

    print("\nğŸ”‘ æ ¸å¿ƒåŸåˆ™:")
    print("  1. æ‰€æœ‰ NotifyStreamEvent éƒ½æ˜¯çº¯å±•ç¤ºæ€§è´¨ï¼Œä¸å½±å“å¯¹è¯å†å²")
    print("  2. åªæœ‰æœ€åçš„ yield 'å­—ç¬¦ä¸²' ä¼šè¢«è®°å½•ä¸ºå·¥å…·è¾“å‡º")
    print("  3. yield 'å­—ç¬¦ä¸²' æ˜¯ç»ˆç»“ä¿¡å·ï¼Œä¹‹åçš„yieldä¼šè¢«å¿½ç•¥")


if __name__ == "__main__":
    """è¿è¡Œå®Œæ•´çš„@streaming_toolæ¼”ç¤ºå¥—ä»¶"""
    async def main():
        await demo_core_scenarios()
        await demo_agent_as_tool()
        await demo_direct_tool_calls()
        await demo_quick_reference()

        print("\n" + "=" * 80)
        print("ğŸ‰ @streaming_tool æ¼”ç¤ºå®Œæˆï¼")
        print("ğŸ“š æ›´å¤šä¿¡æ¯è¯·å‚è€ƒ: docs/tools.md")
        print("=" * 80)

    asyncio.run(main())
