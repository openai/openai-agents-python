# Streaming

Streaming lets you subscribe to updates of the agent run as it proceeds. This can be useful for showing the end-user progress updates and partial responses.

To stream, you can call [`Runner.run_streamed()`][agents.run.Runner.run_streamed], which will give you a [`RunResultStreaming`][agents.result.RunResultStreaming]. Calling `result.stream_events()` gives you an async stream of [`StreamEvent`][agents.stream_events.StreamEvent] objects, which are described below.

## Raw response events

[`RawResponsesStreamEvent`][agents.stream_events.RawResponsesStreamEvent] are raw events passed directly from the LLM. They are in OpenAI Responses API format, which means each event has a type (like `response.created`, `response.output_text.delta`, etc) and data. These events are useful if you want to stream response messages to the user as soon as they are generated.

For example, this will output the text generated by the LLM token-by-token.

```python
import asyncio
from openai.types.responses import ResponseTextDeltaEvent
from agents import Agent, Runner

async def main():
    agent = Agent(
        name="Joker",
        instructions="You are a helpful assistant.",
    )

    result = Runner.run_streamed(agent, input="Please tell me 5 jokes.")
    async for event in result.stream_events():
        if event.type == "raw_response_event" and isinstance(event.data, ResponseTextDeltaEvent):
            print(event.data.delta, end="", flush=True)


if __name__ == "__main__":
    asyncio.run(main())
```

### Function call argument streaming

Function call arguments are now streamed in real-time as they are generated, providing immediate feedback during large parameter generation. This is especially useful for scenarios like code generation, API request building, or complex configuration creation.

```python
import asyncio
from openai.types.responses import ResponseFunctionCallArgumentsDeltaEvent
from agents import Agent, Runner, function_tool

@function_tool
def write_file(filename: str, content: str) -> str:
    """Write content to a file."""
    return f"File {filename} written successfully"

async def main():
    agent = Agent(
        name="CodeGenerator",
        instructions="You are a helpful coding assistant. When asked to create files, use the write_file tool.",
        tools=[write_file],
    )

    result = Runner.run_streamed(
        agent,
        input="Create a Python script that prints 'Hello, World!' and saves it as hello.py"
    )

    function_name = None
    current_arguments = ""

    async for event in result.stream_events():
        if event.type == "raw_response_event":
            # Function call started
            if event.data.type == "response.output_item.added":
                if getattr(event.data.item, "type", None) == "function_call":
                    function_name = event.data.item.name
                    print(f"ğŸ“ Function call streaming started: {function_name}()")
                    print("ğŸ“ Arguments building...")

            # Real-time argument streaming
            elif isinstance(event.data, ResponseFunctionCallArgumentsDeltaEvent):
                current_arguments += event.data.delta
                print(f"   + {event.data.delta}", end="", flush=True)

            # Function call completed
            elif event.data.type == "response.output_item.done":
                if hasattr(event.data.item, 'name'):
                    print(f"\nâœ… Function call streaming completed: {function_name}")
                    print(f"ğŸ”§ Final arguments: {current_arguments}")

    print(f"\nğŸ‰ Result: {result.final_output}")


if __name__ == "__main__":
    asyncio.run(main())
```

This will show the function arguments being built incrementally:
```
ğŸ“ Function call streaming started: write_file()
ğŸ“ Arguments building...
   + {"filename": "
   + hello.py", "content": "
   + print('Hello, World!')"}
âœ… Function call streaming completed: write_file
ğŸ”§ Final arguments: {"filename": "hello.py", "content": "print('Hello, World!')"}
```

## Run item events and agent events

[`RunItemStreamEvent`][agents.stream_events.RunItemStreamEvent]s are higher level events. They inform you when an item has been fully generated. This allows you to push progress updates at the level of "message generated", "tool ran", etc, instead of each token. Similarly, [`AgentUpdatedStreamEvent`][agents.stream_events.AgentUpdatedStreamEvent] gives you updates when the current agent changes (e.g. as the result of a handoff).

For example, this will ignore raw events and stream updates to the user.

```python
import asyncio
import random
from agents import Agent, ItemHelpers, Runner, function_tool

@function_tool
def how_many_jokes() -> int:
    return random.randint(1, 10)


async def main():
    agent = Agent(
        name="Joker",
        instructions="First call the `how_many_jokes` tool, then tell that many jokes.",
        tools=[how_many_jokes],
    )

    result = Runner.run_streamed(
        agent,
        input="Hello",
    )
    print("=== Run starting ===")

    async for event in result.stream_events():
        # We'll ignore the raw responses event deltas
        if event.type == "raw_response_event":
            continue
        # When the agent updates, print that
        elif event.type == "agent_updated_stream_event":
            print(f"Agent updated: {event.new_agent.name}")
            continue
        # When items are generated, print them
        elif event.type == "run_item_stream_event":
            if event.item.type == "tool_call_item":
                print("-- Tool was called")
            elif event.item.type == "tool_call_output_item":
                print(f"-- Tool output: {event.item.output}")
            elif event.item.type == "message_output_item":
                print(f"-- Message output:\n {ItemHelpers.text_message_output(event.item)}")
            else:
                pass  # Ignore other event types

    print("=== Run complete ===")


if __name__ == "__main__":
    asyncio.run(main())
```
